{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fatal-notebook",
   "metadata": {},
   "source": [
    "## Data Science\n",
    "\n",
    "Eric Schmidt, the former CEO of Google: \"Data Science is the Future of Everything\".  https://www.youtube.com/watch?v=9hDnO_ykC7Y."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-stockholm",
   "metadata": {},
   "source": [
    "## Data analytics pipeline\n",
    "\n",
    "Data modeling is the process of using data to build predictive models. Data can also be used for descriptive and prescriptive analysis. But before we make use of data, it has to be fetched from several sources, stored, assimilated, cleaned, and engineered to suit our goal. The sequential operations that need to be performed on data are akin to a manufacturing pipeline, where each subsequent step adds value to the potential end product and each progression requires a new person or skill set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lucky-soccer",
   "metadata": {},
   "source": [
    "The various steps in a data analytics pipeline are shown in the following diagram: \n",
    "\n",
    "<img src=\"../images/ds-pipe.png\" alt=\"ds-steps\" width=600 align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-perception",
   "metadata": {},
   "source": [
    "These steps can be combined into three high-level categories:\n",
    "1. Data engineering\n",
    "2. Data science\n",
    "3. Product development.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-grounds",
   "metadata": {},
   "source": [
    "**Data Engineering** deals with sourcing data from a variety of sources, creating a suitable database and table schema, and loading the data in a suitable database. There can be many approaches to this step depending on the following:\n",
    "\n",
    "- Type of data: Structured (tabular data) versus unstructured (such as images and text) versus semi-structured (such as JSON and XML)\n",
    "- Velocity of data upgrade: Batch processing versus real-time data streaming\n",
    "- Volume of data: Distributed (or cluster-based) storage versus single instance databases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-portrait",
   "metadata": {},
   "source": [
    "**Data Science** is the phase where the data is made usable and used to predict the future, learn patterns, and extrapolate these patterns. Data science can further be sub-divided into two phases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-unknown",
   "metadata": {},
   "source": [
    "**Product Development** is the phase where all the hard work bears fruit and all the insights, results, and patterns are served to the users in a way that they can consume, understand, and act upon. It might range from building a dashboard on data with additional derived fields to an API that calls a trained model and returns an output on incoming data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-paragraph",
   "metadata": {},
   "source": [
    "Apart from these steps in the pipeline, there are some additional steps that might come into the picture. This is due to the highly evolving nature of the data landscape. For example, deep learning, which is used extensively to build intelligent products around image, text, and audio data, often requires the training data to be labeled into a category or augmented if the quantity is too small to create an accurate model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-philosophy",
   "metadata": {},
   "source": [
    "## Why Python\n",
    "\n",
    "Among the characteristics that make Python popular for data science are its very user-friendly (human-readable) syntax, the fact that it is interpreted rather than compiled (leading to faster development time), and it has very comprehensive libraries for parsing and analyzing data, as well as its capacity for numerical and statistical computations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-bishop",
   "metadata": {},
   "source": [
    "Python has libraries that provide a complete toolkit for data science and analysis. The major ones are as follows:\n",
    "\n",
    "- **NumPy**: The general-purpose array functionality with an emphasis on numeric computation\n",
    "- **SciPy**: Numerical computing\n",
    "- **Matplotlib**: Graphics\n",
    "- **pandas**: Series and data frames (1D and 2D array-like types)\n",
    "- **Scikit-learn**: Machine learning\n",
    "- **NLTK**: Natural language processing\n",
    "- **Statstool**: Statistical analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
